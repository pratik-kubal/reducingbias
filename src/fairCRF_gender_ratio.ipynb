{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by Jieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Ordonez, Kai-Wei Chang\n",
    "\n",
    "Reference: [EMNLP 2017 paper](https://arxiv.org/abs/1707.09457)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "Language is increasingly being used to define rich visual recognition problems with\n",
    "supporting image collections sourced from\n",
    "the web. Structured prediction models are\n",
    "used in these tasks to take advantage of\n",
    "correlations between co-occurring labels\n",
    "and visual input but risk inadvertently encoding\n",
    "social biases found in web corpora.\n",
    "In this work, we study data and models associated\n",
    "with multilabel object classification\n",
    "and visual semantic role labeling. We\n",
    "find that (a) datasets for these tasks contain\n",
    "significant gender bias and (b) models\n",
    "trained on these datasets further amplify\n",
    "existing bias. For example, the activity\n",
    "cooking is over 33% more likely\n",
    "to involve females than males in a training\n",
    "set, and a trained model further amplifies the disparity to 68% at test time. We\n",
    "propose to inject corpus-level constraints\n",
    "for calibrating existing structured prediction\n",
    "models and design an algorithm based\n",
    "on Lagrangian relaxation for collective inference.\n",
    "Our method results in almost no\n",
    "performance loss for the underlying recognition\n",
    "task but decreases the magnitude of\n",
    "bias amplification by 47.5% and 40.5% for\n",
    "multilabel classification and visual semantic\n",
    "role labeling, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Motivation: Let's take a look at the visual semantic role labeling (vSRL) task \n",
    "\n",
    "The visual semantic labeling (vSRL) tasks aim at extracting rich semantics\n",
    "from images and require large quantities of labeled\n",
    "data, predominantly retrieved from the web. Each image\n",
    "is paired with a table describing a situation: the verb, cooking, its semantic roles, i.e agent, and\n",
    "noun values filling that role, i.e. woman. The following figure demonstrate a few examples predicted by a vSRL system.\n",
    "\n",
    "![Examples from vSRL dataset.](../img/bias_teaser.png)\n",
    "*Figure 1: Examples from vSRL dataset. All the tables are the predicted results for the corresponding imagess. *\n",
    "\n",
    "\n",
    "Methods often combine structured prediction and\n",
    "deep learning to model correlations between labels\n",
    "and images to make judgments that otherwise\n",
    "would have weak visual support. For example, in\n",
    "the first image of Figure 1, it is possible to predict\n",
    "a spatula by considering that it is a common\n",
    "tool used for the activity cooking. Yet such\n",
    "methods run the risk of discovering and exploiting\n",
    "societal biases present in the underlying web corpora.\n",
    "Without properly quantifying and reducing\n",
    "the reliance on such correlations, broad adoption\n",
    "of these models can have the inadvertent effect of\n",
    "magnifying stereotypes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualizing and Quantifying Biases\n",
    "\n",
    "In this paper, we develop a general framework for quantifying bias and study two concrete tasks, visual semantic role labeling (vSRL) and multilabel object classification (MLC). We use gender bias as a running example and show that both supporting datasets for these tasks are biased with respect to a gender binary. Our analysis reveals that over 50% and 40% of verbs and objects, respectively, exhibit bias toward a gender greater than 2:1. For example, as seen in Figure 1, the cooking activity in imSitu is a heavily biased verb. Furthermore, we show that after training state-of-the-art structured predictors, models amplify the existing bias, by 5.0% for vSRL, and 3.2% in MLC.\n",
    "\n",
    "Here we show the amplified bias in the model. The x-axis is the training gender ratio, y-axis is the predicted gender ratio. The solid blue line is the result that each verb's gender ratio equals to the trainig ratio. All the dots are the predicted results in the development dataset. A gender ratio closer to 1 means this verb is more biased to male. We can see that in both male and female direction, the bias is amplified -- the predicted gender ratio is even more biased to the corresponding gender. We first provide the result on vSRL task and then show the result for MLC. The helper functions defined in fairCRF_utils.py and inference_debias.py can be found [here](fairCRF_utils.py) (fairCRF_utils) and [here](inference_debias.py) (inference_debias). All the files needed for MLC task are under [data](../data/COCO) folder. While the potential files for vSRL task is too large to put here, you can get the sampled potential files and other files [here](../data/imSitu). If you want to try the whole vSRL dataset, you can get it [here](https://s3.amazonaws.com/MY89_Transfer/webly_crf_output.tar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess\n",
    "import fairCRF_utils as myutils\n",
    "import inference_debias as cocoutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "myutils.set_GPU(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Bias in  vSRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start loading potential files\n",
      ". . . . . . . . . . . \n",
      "Finish loading dev potential files\n"
     ]
    }
   ],
   "source": [
    "margin = 0.05\n",
    "vSRL = 1\n",
    "is_dev = 1\n",
    "myutils.show_amplified_bias(margin, vSRL, is_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### imSitu is biased.\n",
    "In the above figure, along the x-axis, we show the male favoring bias of imSitu verbs. Overall, the dataset is heavily biased toward male agents, with 64.6% of verbs favoring a male agent by an average bias of 0.707 (roughly 3:1 male). Nearly half of verbs are extremely biased in the male or female direction: 46.95% of verbs favor a gender with a bias of at least 0.7. Also it contains several activity labels revealing problematic biases. For example, \"shopping\" and \"washing\" are biased toward a female agent. Furthermore, several verbs such as \"driving\" and \"coaching\" are heavily biased toward a male agent.\n",
    "#### Training on imSitu amplifies bias.\n",
    "Also in this figure, along the y-axis, we show the ratio of male agents (% of total people) in predictions on an unseen development set. The mean bias ampli- fication in the development set is high, 0.050 on average, with 45.75% of verbs exhibiting amplification. Biased verbs tend to have stronger amplification: verbs with training bias over 0.7 in either the male or female direction have a mean amplification of 0.072. Several already problematic biases have gotten much worse. For example, serving, only had a small bias toward females in the training set, 0.402, is now heavily biased toward females, 0.122. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Bias in MLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 0.05\n",
    "vSRL = 0\n",
    "is_dev = 1\n",
    "myutils.show_amplified_bias(margin, vSRL, is_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can see in the MLC result that MS-COCO is gender biased and training on MS-COCO amplifies bias. This data is even more heavily biased toward men than imSitu, with 86.6% of objects biased toward men. One third of the nouns are extremely biased toward males, 37.9% of nouns favor men with a bias of at least 0.7. Also, along the y-axis, we show the ratio of man (% of both gender) in predictions on an unseen development set. The mean bias amplification across all objects is 0.036, with 65.67% of nouns exhibiting amplification. Larger training bias again tended to indicate higher bias amplifi- cation: biased objects with training bias over 0.7 had mean amplification of 0.081."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calibration Algorithm\n",
    "To mitigate the role of bias amplification when training models on biased corpora, we propose a novel constrained inference framework, called RBA, for Reducing Bias Amplification in predictions. Our method introduces corpus-level constraints so that gender indicators co-occur no more often together with elements of the prediction task than in the original training distribution. We combine our calibration constraint with the original structured predictor and use Lagrangian relaxation to reweigh bias creating factors in the original model. The results show that our algorithm can efficiently reduce the amplifed bias while doesn't hurt much to the performance, approximately only 0.2% difference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### <span style=\"color:blue\"> 3.1 Reducing Bias Amplification (RBA) </span> \n",
    "The first goal is to collect the statistics in the training data in order to generate reference gender ratio for each first. Then we can design  corpus-level constrints to ensure the gender ratio for each verb is within the margin of the corresponding reference ratio. In vSRL, we get the constraints for each verb as {verb_id: ((m_c1, f_c1), (m_c2, f_c2), val)}.  (m_c1,f_c1) is for the constraint: $\\frac{m}{m+f} \\geq tr - \\epsilon$ and (m_c2,f_c2) is for the constraint: $\\frac{m}{m+f} \\leq tr + \\epsilon$. Here $tr$ refers to the training gender ratio. For the first one, we get $(tr-\\epsilon-1)\\cdot m + (tr-\\epsilon)\\cdot f \\leq val$. Here $\\epsilon$ is the margin that user can set. In MLC, the constraints have the same format except that each verb should be each object.\n",
    "\n",
    "\n",
    "We add some constraints to the verbs we considered: in the training time, this verb should have at least #num_gender agents is a man or woman; and in the predictions, m+f > #num_cons_verb. We add these constraints because we want to make sure that this verb is related to gender otherwise it will be difficult to change the gender ratio, for example if this verb only have one \"man\" agent, it will be impossible to calibrate the gender ratio. As we described in our paper, in the end, we focus on 212 verbs and 66 objects.\n",
    "\n",
    "<img src=\"../img/constraints_show.png\" width=\"450\">\n",
    "*Figure 2: Example for vSRL constraints. In the figure, the x-axis is the training gender ratio, the y-axis is the predicted gender ratio. The solid blue line is the reference ratio (predicted gender ratio equals to the training gender ratio). The dashed blue lines are the margins that user can define. Green dots mean these verbs are satisfied with the constraints while the red ones mean the verbs violate the constraints and need to be calibrated.*\n",
    "\n",
    "\n",
    "\n",
    "#### <span style=\"color:blue\"> Lagrangian for calibrating </span> \n",
    "The optimal object is: $L(\\lambda, y) = f(y) - \\sum_k \\lambda_k(\\sum_{i,r}c_k\\cdot y_{i,r}-val), \\forall k, \\lambda_k \\geq 0$. Here $val = 0$ (we can get from the constraints), $i$ stands for each instance and $r$ stands for each role. \n",
    "\n",
    "1) First do the original inference;\n",
    "\n",
    "2) Using the inference results to update the lambdas: $\\lambda_k = \\lambda_k - \\eta * (-\\sum_{i,r}c_k\\cdot y_{i,r})$ \n",
    "\n",
    "3) Update the coresponding $y_{i,r}$: $y_{i,r} = (s_0 - \\lambda_k\\cdot c_k)\\cdot y_{i,r}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **<span style=\"color:blue\">lagrange_with_margins</span>** function takes these parameters: margin, eta, constraints, inference, get_acc, get_update_index, all_man_idx, all_woman_idx, arg_inner_all, vSRL, \\*args. \n",
    "- **margin** is a float number, which refers to the $\\epsilon$ in the constraints above. \n",
    "- **eta** is the learning rate for the algorithm.\n",
    "- **constraints** is a dictionary following the above format. \n",
    "- **inference** is your own inference algorithm which will return a top1 result and a dictionary {obj:[#man, #woman]}. If your inference algorithm provides several predictions, top1 just picks the most likely one. The dictionary contains the information of how many times the object is related to **man** and **woman**. In imSitu dataset, the obj refers to the **verb** while in MS-COCO dataset, it means the detected **objection**. \n",
    "- **get_acc** is the function to calculate the current accuracy of the prediction. \n",
    "- **get_update_index** is the function identifying which lagrangian multipliers need updating.\n",
    "- **all_man_idx** and **all_woman_idx** are two lists used to update the Lagrangian multipliers. In imSitu they refer to the index in the role_potential_file that this entry refers to a man or woman \"agent\". In COCO, it refers to the index related to man or woman images. You can define your own idx lists as long as they relates to all man and woman related items respectively. \n",
    "- **arg_inner_all** is the potential scores used for inference and calcuating the accuracy. This can be get from the prediction system. The potential scores are 2d-arrays, each entry stands for the potential scores for one instance. Based on different applications, you may need several potential files to get the inference or the accuracy. For example, in vSRL, we need arg_inner_all(related to all the roles), value_frame_inner_all(related to the verbs), label_all(related to the true label), while in MLC we only need arg_inner_all. \n",
    "- **vSRL** is a flag to tell the system which task(vSRL/MLC) to run.\n",
    "- **\\*arg** refers to other parameters that you may need to get the inference results or the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def lagrange_with_margins(margin, eta, constraints, inference, get_acc, get_update_index, \n",
    "                          all_man_idx, all_woman_idx, arg_inner_all, vSRL, *args):\n",
    "    lambdas = {item:[0,0] for item in constraints}\n",
    "    arg_inner_tmp = arg_inner_all.copy()\n",
    "    results = []\n",
    "    if vSRL == 1:\n",
    "        inf_arg = (args[0:-1])\n",
    "        acc_arg = (args[0:2]) + (args[-1],)\n",
    "    else:\n",
    "        inf_arg = \"\"\n",
    "        acc_arg = (args[0],)\n",
    "        \n",
    "    print \"Starting Lagrangian part\"     \n",
    "    for epoch in range(100):\n",
    "        count = 0\n",
    "        error = {item:[0,0] for item in constraints}\n",
    "\n",
    "        top1, pred_agents = inference(arg_inner_tmp, *inf_arg) \n",
    "        non_zeros = {}\n",
    "        for k in constraints:\n",
    "            if k in pred_agents:\n",
    "                    lambdas[k][0] += eta * constraints[k][0][0] * pred_agents[k][0]\n",
    "                    lambdas[k][1] += eta * constraints[k][1][0] * pred_agents[k][0]\n",
    "                    error[k][0] += constraints[k][0][0] * pred_agents[k][0]\n",
    "                    error[k][1] +=  constraints[k][1][0] * pred_agents[k][0]\n",
    "                    lambdas[k][0] += eta * constraints[k][0][1] * pred_agents[k][1]\n",
    "                    lambdas[k][1] += eta * constraints[k][1][1] * pred_agents[k][1]\n",
    "                    error[k][0] += constraints[k][0][1] *  pred_agents[k][1]\n",
    "                    error[k][1] +=  constraints[k][1][1] *  pred_agents[k][1]\n",
    "        \n",
    "        for k in lambdas:\n",
    "            for i in range(2):\n",
    "                if lambdas[k][i] <= 0:\n",
    "                    lambdas[k][i] = 0\n",
    "\n",
    "        for k in error:\n",
    "            for i in range(2):\n",
    "                if error[k][i] > 0:\n",
    "                    count += 1\n",
    "\n",
    "        arg_inner_tmp = arg_inner_all.copy()\n",
    "\n",
    "        for i in range(len(arg_inner_tmp)):\n",
    "            for arg_idx in top1[i][1]:\n",
    "                if arg_idx in all_man_idx:\n",
    "                    k = get_update_index(top1, i, arg_idx, 1, vSRL)\n",
    "                    if k in lambdas:  \n",
    "                        arg_inner_tmp[i][arg_idx] -= lambdas[k][0] * constraints[k][0][0] \n",
    "                        arg_inner_tmp[i][arg_idx] -= lambdas[k][1] * constraints[k][1][0]\n",
    "                if arg_idx in all_woman_idx:\n",
    "                    k = get_update_index(top1, i, arg_idx, 0, vSRL)\n",
    "                    if k in lambdas: \n",
    "                        arg_inner_tmp[i][arg_idx] -= lambdas[k][0] * constraints[k][0][1] \n",
    "                        arg_inner_tmp[i][arg_idx] -= lambdas[k][1] * constraints[k][1][1]\n",
    "\n",
    "        if epoch % 10 == 0 or epoch == 99:\n",
    "            print \"%s-th epoch, number of times that constrints are not satisfied:\"%(epoch), count\n",
    "            acc1 = get_acc(arg_inner_tmp, *acc_arg)\n",
    "            print \"%s-epoch, acc is: \"%(epoch),acc1\n",
    "            results.append([epoch, count, acc1])\n",
    "            \n",
    "        if count == 0:\n",
    "            break\n",
    "    myutils.save_iterations(myutils.configs['save_iteration'] + \"_margin_\" + str(margin), results)\n",
    "    myutils.save_lambdas(myutils.configs['save_lambda'] + \"_margin_\" + str(margin), lambdas)\n",
    "    return arg_inner_tmp, lambdas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\"> 3.2 Running example </span>\n",
    "Here we give an example of running the calibrating function in vSRL and MLC tasks. **vSRL** is used to define which task to run. And you can set your own **margin** and **eta**. **is_dev** defines which dataset (development, test) we want to use. (Remember to change the file path in config.ini. Using the absolute path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run(margin, vSRL, is_dev, eta):\n",
    "    reargs = mypreprocess.preprocess(margin, vSRL, is_dev)\n",
    "    if vSRL != 1:\n",
    "        eta = 0.05\n",
    "        (constraints, all_man_idx, all_woman_idx, arg_inner_all, \n",
    "         target, pred_objs_bef, cons_verbs, train_samples) = reargs\n",
    "        arg_inner_tmp, lambdas = lagrange_with_margins(margin, eta, constraints, \n",
    "                                                       cocoutils.inference, cocoutils.accuracy,\n",
    "                                                       myutils.get_update_index, all_man_idx, \n",
    "                                                       all_woman_idx, arg_inner_all, vSRL, target)\n",
    "        \n",
    "        mypreprocess.show_results(margin, vSRL, arg_inner_tmp, cons_verbs, \n",
    "                                  train_samples, pred_objs_bef)\n",
    "    else:\n",
    "        eta = 0.1\n",
    "        (arg_inner_all, value_frame_all, label_all, len_verb_file, all_man_idx, all_woman_idx, \n",
    "         constraints, output_index, id_verb, verb_roles, cons_verbs, num_gender,words_file, \n",
    "         training_file, role_potential_file, verb_id) = reargs\n",
    "        value_frame_tmp = value_frame_all.copy()\n",
    "        label = label_all.copy()\n",
    "        arg_inner_tmp, lambdas = lagrange_with_margins(margin, eta, constraints, \n",
    "                                                       myutils.inference, myutils.get_acc, \n",
    "                                                       myutils.get_update_index,\n",
    "                                                       all_man_idx, all_woman_idx, arg_inner_all, \n",
    "                                                       vSRL, value_frame_tmp, label,output_index, \n",
    "                                                       id_verb, verb_roles, len_verb_file)\n",
    "        \n",
    "        mypreprocess.show_results(margin, vSRL, cons_verbs, num_gender, words_file, \n",
    "                                  training_file, role_potential_file, arg_inner_all, value_frame_all,\n",
    "                                  label_all, arg_inner_tmp, value_frame_all, output_index, id_verb, \n",
    "                                  verb_id, verb_roles)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Calibration for vSRL\n",
    "\n",
    "We run the RBA algorithm on vSRL task. The following three images show the result for RBA algorithm. The first image shows the prediction before adopting RBA. The second one shows the result after RBA.  The x-axis is the training gender ratio, the y-axis is the predicted gender ratio. The solid blue line is the reference ratio. We can see that after RBA, the predicted ratio gets closer to the reference ratio, which means we can efficiently reduce the amplified bias. The third figure demonstrate bias amplification as a function of training bias, with (blue line) and without (red line) RBA. Here y-axis is the mean amplified bias for a fixed window of verbs. We can see that across all initial training biases, RBA is able to reduce the bias amplification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "margin = 0.05\n",
    "is_dev = 1\n",
    "run(margin, 1, is_dev, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Calibration for MLC\n",
    "In this section we show the result for adopting RBA in MLC. The results are similar to that in vSRL task. Again, we can efficiently reduce the amplified bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "margin = 0.05\n",
    "is_dev = 1\n",
    "run(margin, 0, is_dev, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
